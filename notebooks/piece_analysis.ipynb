{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ Norwegian Wind Band Competition - Musical Piece Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of musical pieces performed in Norwegian Wind Band competitions from 1981-2025, including:\n",
    "\n",
    "- **Piece popularity and success rates** across 40+ years\n",
    "- **Grade level analysis** for difficulty-appropriate repertoire selection\n",
    "- **Set test piece detection** and impact on competition dynamics\n",
    "- **Duration and time constraint analysis** for program optimization\n",
    "- **Division-specific trends** and repertoire evolution\n",
    "\n",
    "**Data Sources:**\n",
    "- 911 unique pieces from competition database\n",
    "- 2,338 total performances tracked\n",
    "- WindRep.org metadata enrichment\n",
    "- 40 suspected mandatory pieces identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.nmjanitsjar_scraper.piece_analysis import PieceAnalyzer, DivisionConstraints\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"üéº Norwegian Wind Band Competition Analysis\")\n",
    "print(\"üìä Analyzing 40+ years of competition data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer and load all data\n",
    "analyzer = PieceAnalyzer()\n",
    "\n",
    "# Get comprehensive piece analysis\n",
    "print(\"Loading and analyzing all competition data...\")\n",
    "all_pieces = analyzer.analyze_piece_popularity()\n",
    "\n",
    "print(f\"‚úì Loaded {len(all_pieces)} unique pieces\")\n",
    "print(f\"‚úì Total performances: {sum(p.performance_count for p in all_pieces.values()):,}\")\n",
    "print(f\"‚úì Average performances per piece: {sum(p.performance_count for p in all_pieces.values()) / len(all_pieces):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "pieces_data = []\n",
    "for piece in all_pieces.values():\n",
    "    pieces_data.append({\n",
    "        'title': piece.title,\n",
    "        'composer': piece.composer,\n",
    "        'performances': piece.performance_count,\n",
    "        'wins': int(piece.performance_count * piece.win_rate / 100),\n",
    "        'win_rate': piece.win_rate,\n",
    "        'avg_points': piece.avg_points,\n",
    "        'duration_minutes': piece.duration_minutes,\n",
    "        'grade_level': piece.grade_level,\n",
    "        'difficulty': piece.difficulty,\n",
    "        'category': piece.category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(pieces_data)\n",
    "print(f\"üìä DataFrame created with {len(df)} pieces\")\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"üéØ Basic Statistics:\")\n",
    "print(f\"Performance count range: {df['performances'].min()} - {df['performances'].max()}\")\n",
    "print(f\"Win rate range: {df['win_rate'].min():.1f}% - {df['win_rate'].max():.1f}%\")\n",
    "print(f\"Average points range: {df['avg_points'].min():.1f} - {df['avg_points'].max():.1f}\")\n",
    "\n",
    "# Show sample of data\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Most Popular Pieces Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most popular pieces (3+ performances)\n",
    "popular_pieces = analyzer.get_most_popular_pieces(min_performances=3)\n",
    "print(f\"üèÜ Found {len(popular_pieces)} popular pieces (3+ performances)\")\n",
    "\n",
    "# Create DataFrame for popular pieces\n",
    "popular_df = pd.DataFrame([{\n",
    "    'title': p.title,\n",
    "    'composer': p.composer,\n",
    "    'performances': p.performance_count,\n",
    "    'wins': int(p.performance_count * p.win_rate / 100),\n",
    "    'win_rate': p.win_rate,\n",
    "    'avg_points': p.avg_points\n",
    "} for p in popular_pieces])\n",
    "\n",
    "print(\"\\nüéµ Top 15 Most Popular Pieces:\")\n",
    "display(popular_df.head(15).style.format({\n",
    "    'win_rate': '{:.1f}%',\n",
    "    'avg_points': '{:.1f}'\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Performance count distribution\n",
    "axes[0,0].hist(df['performances'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_xlabel('Performance Count')\n",
    "axes[0,0].set_ylabel('Number of Pieces')\n",
    "axes[0,0].set_title('Distribution of Performance Counts')\n",
    "axes[0,0].axvline(df['performances'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {df[\"performances\"].mean():.1f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Win rate distribution\n",
    "win_rates = df[df['win_rate'] > 0]['win_rate']  # Only pieces with wins\n",
    "axes[0,1].hist(win_rates, bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[0,1].set_xlabel('Win Rate (%)')\n",
    "axes[0,1].set_ylabel('Number of Pieces')\n",
    "axes[0,1].set_title('Distribution of Win Rates (Pieces with Wins Only)')\n",
    "axes[0,1].axvline(win_rates.mean(), color='red', linestyle='--',\n",
    "                  label=f'Mean: {win_rates.mean():.1f}%')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Performance vs Win Rate scatter\n",
    "successful_pieces = df[df['performances'] >= 3]  # Focus on pieces with enough data\n",
    "axes[1,0].scatter(successful_pieces['performances'], successful_pieces['win_rate'], \n",
    "                  alpha=0.6, color='orange')\n",
    "axes[1,0].set_xlabel('Performance Count')\n",
    "axes[1,0].set_ylabel('Win Rate (%)')\n",
    "axes[1,0].set_title('Performance Count vs Win Rate')\n",
    "\n",
    "# Top composers by piece count\n",
    "composer_counts = df['composer'].value_counts().head(10)\n",
    "axes[1,1].barh(composer_counts.index, composer_counts.values, color='lightcoral')\n",
    "axes[1,1].set_xlabel('Number of Pieces')\n",
    "axes[1,1].set_title('Top 10 Composers by Piece Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WindRep.org Data Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich top pieces with WindRep data\n",
    "print(\"üåê Enriching top 25 pieces with WindRep.org metadata...\")\n",
    "enriched_pieces = analyzer.enrich_with_windrep_data(popular_pieces[:25], max_pieces=25)\n",
    "\n",
    "# Create DataFrame for enriched data\n",
    "enriched_df = pd.DataFrame([{\n",
    "    'title': p.title,\n",
    "    'composer': p.composer,\n",
    "    'performances': p.performance_count,\n",
    "    'win_rate': p.win_rate,\n",
    "    'avg_points': p.avg_points,\n",
    "    'duration_minutes': p.duration_minutes,\n",
    "    'grade_level': p.grade_level,\n",
    "    'difficulty': p.difficulty,\n",
    "    'windrep_url': p.windrep_url\n",
    "} for p in enriched_pieces])\n",
    "\n",
    "# Count successful enrichments\n",
    "with_url = enriched_df['windrep_url'].notna().sum()\n",
    "with_duration = enriched_df['duration_minutes'].notna().sum()\n",
    "with_grade = enriched_df['grade_level'].notna().sum()\n",
    "\n",
    "print(f\"‚úì {with_url}/{len(enriched_df)} pieces found on WindRep.org\")\n",
    "print(f\"‚úì {with_duration}/{len(enriched_df)} pieces with duration data\")\n",
    "print(f\"‚úì {with_grade}/{len(enriched_df)} pieces with grade level data\")\n",
    "\n",
    "# Show enriched data\n",
    "print(\"\\nüéº Enriched Pieces with Metadata:\")\n",
    "enriched_display = enriched_df[enriched_df['duration_minutes'].notna() | \n",
    "                              enriched_df['grade_level'].notna()].copy()\n",
    "if not enriched_display.empty:\n",
    "    display(enriched_display[['title', 'composer', 'performances', 'duration_minutes', \n",
    "                             'grade_level', 'difficulty']].style.format({\n",
    "        'duration_minutes': '{:.1f} min',\n",
    "        'grade_level': lambda x: f'Grade {int(x)}' if pd.notna(x) else 'Unknown'\n",
    "    }))\nelse:\n",
    "    print(\"No pieces with duration or grade level data found in this sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize enriched data\n",
    "if with_duration > 0 or with_grade > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Duration analysis\n",
    "    if with_duration > 0:\n",
    "        duration_data = enriched_df[enriched_df['duration_minutes'].notna()]\n",
    "        axes[0].scatter(duration_data['performances'], duration_data['duration_minutes'], \n",
    "                       s=100, alpha=0.7, color='purple')\n",
    "        for i, row in duration_data.iterrows():\n",
    "            axes[0].annotate(row['title'][:20], \n",
    "                           (row['performances'], row['duration_minutes']),\n",
    "                           xytext=(5, 5), textcoords='offset points', \n",
    "                           fontsize=9, alpha=0.8)\n",
    "        axes[0].set_xlabel('Performance Count')\n",
    "        axes[0].set_ylabel('Duration (minutes)')\n",
    "        axes[0].set_title('Piece Duration vs Popularity')\n",
    "        \n",
    "        # Add division time constraint lines\n",
    "        constraints = DivisionConstraints.get_constraints()\n",
    "        for div_name, constraint in constraints.items():\n",
    "            axes[0].axhline(y=constraint.max_minutes, color='red', linestyle='--', \n",
    "                           alpha=0.5, label=f'{div_name}: {constraint.max_minutes} min')\n",
    "        axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    else:\n",
    "        axes[0].text(0.5, 0.5, 'No duration data available', \n",
    "                    transform=axes[0].transAxes, ha='center', va='center')\n",
    "        axes[0].set_title('Duration Analysis (No Data)')\n",
    "    \n",
    "    # Grade level analysis\n",
    "    if with_grade > 0:\n",
    "        grade_data = enriched_df[enriched_df['grade_level'].notna()]\n",
    "        grade_counts = grade_data['grade_level'].value_counts().sort_index()\n",
    "        axes[1].bar(grade_counts.index, grade_counts.values, color='teal', alpha=0.7)\n",
    "        axes[1].set_xlabel('Grade Level')\n",
    "        axes[1].set_ylabel('Number of Pieces')\n",
    "        axes[1].set_title('Distribution of Grade Levels')\n",
    "        axes[1].set_xticks(range(1, 8))\n",
    "        axes[1].set_xticklabels([f'Grade {i}' for i in range(1, 8)])\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'No grade level data available', \n",
    "                    transform=axes[1].transAxes, ha='center', va='center')\n",
    "        axes[1].set_title('Grade Level Analysis (No Data)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"No enriched data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Test Piece Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze suspected set test pieces\n",
    "print(\"üîç Analyzing suspected set test pieces...\")\n",
    "set_pieces = analyzer.analyze_set_test_pieces()\n",
    "\n",
    "print(f\"Found {len(set_pieces)} year-division combinations with suspected set pieces\")\n",
    "total_suspected = sum(len(pieces) for pieces in set_pieces.values())\n",
    "print(f\"Total suspected mandatory pieces: {total_suspected}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "set_pieces_data = []\n",
    "for key, pieces in set_pieces.items():\n",
    "    for piece in pieces:\n",
    "        set_pieces_data.append(piece)\n",
    "\n",
    "set_df = pd.DataFrame(set_pieces_data)\n",
    "\n",
    "if not set_df.empty:\n",
    "    print(\"\\nüéØ Top Suspected Set Test Pieces (100% performance rate):\")\n",
    "    perfect_scores = set_df[set_df['percentage_of_division'] == 100.0]\n",
    "    display(perfect_scores[['year', 'division', 'title', 'composer', 'performances']].head(10))\nelse:\n",
    "    print(\"No set test pieces identified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize set test piece patterns\n",
    "if not set_df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Set pieces by year\n",
    "    year_counts = set_df['year'].value_counts().sort_index()\n",
    "    axes[0,0].bar(year_counts.index, year_counts.values, color='crimson', alpha=0.7)\n",
    "    axes[0,0].set_xlabel('Year')\n",
    "    axes[0,0].set_ylabel('Number of Suspected Set Pieces')\n",
    "    axes[0,0].set_title('Suspected Set Test Pieces by Year')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Set pieces by division\n",
    "    division_counts = set_df['division'].value_counts()\n",
    "    axes[0,1].bar(division_counts.index, division_counts.values, color='orange', alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Division')\n",
    "    axes[0,1].set_ylabel('Number of Suspected Set Pieces')\n",
    "    axes[0,1].set_title('Suspected Set Test Pieces by Division')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Performance percentage distribution\n",
    "    axes[1,0].hist(set_df['percentage_of_division'], bins=20, color='green', alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Percentage of Division (%)')\n",
    "    axes[1,0].set_ylabel('Number of Pieces')\n",
    "    axes[1,0].set_title('Distribution of Performance Percentages')\n",
    "    axes[1,0].axvline(100, color='red', linestyle='--', label='100% (Definitely mandatory)')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Most common set piece composers\n",
    "    composer_counts = set_df['composer'].value_counts().head(8)\n",
    "    axes[1,1].barh(composer_counts.index, composer_counts.values, color='purple', alpha=0.7)\n",
    "    axes[1,1].set_xlabel('Number of Suspected Set Pieces')\n",
    "    axes[1,1].set_title('Composers Most Featured in Set Pieces')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show timeline of set pieces\n",
    "    print(\"\\nüìÖ Timeline of Suspected Set Test Pieces:\")\n",
    "    timeline = set_df[set_df['percentage_of_division'] == 100.0].sort_values('year')\n",
    "    for _, row in timeline.iterrows():\n",
    "        print(f\"{row['year']} - {row['division']}: '{row['title']}' by {row['composer']} ({row['performances']} performances)\")\nelse:\n",
    "    print(\"No set test piece data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Success Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highest success rate pieces\n",
    "successful_pieces = analyzer.get_highest_success_pieces(min_performances=2)\n",
    "print(f\"üèÜ Found {len(successful_pieces)} pieces with success data (2+ performances)\")\n",
    "\n",
    "# Create DataFrame for successful pieces\n",
    "success_df = pd.DataFrame([{\n",
    "    'title': p.title,\n",
    "    'composer': p.composer,\n",
    "    'performances': p.performance_count,\n",
    "    'wins': int(p.performance_count * p.win_rate / 100),\n",
    "    'win_rate': p.win_rate,\n",
    "    'avg_points': p.avg_points\n",
    "} for p in successful_pieces if p.win_rate > 0])  # Only pieces with wins\n",
    "\n",
    "print(\"\\nüéñÔ∏è Top 15 Most Successful Pieces:\")\n",
    "display(success_df.head(15).style.format({\n",
    "    'win_rate': '{:.1f}%',\n",
    "    'avg_points': '{:.1f}'\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success rate analysis visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Success rate vs performance count\n",
    "axes[0,0].scatter(success_df['performances'], success_df['win_rate'], \n",
    "                  s=60, alpha=0.7, color='gold')\n",
    "axes[0,0].set_xlabel('Performance Count')\n",
    "axes[0,0].set_ylabel('Win Rate (%)')\n",
    "axes[0,0].set_title('Win Rate vs Performance Count')\n",
    "\n",
    "# Average points vs win rate\n",
    "valid_points = success_df[success_df['avg_points'].notna()]\n",
    "if not valid_points.empty:\n",
    "    axes[0,1].scatter(valid_points['win_rate'], valid_points['avg_points'], \n",
    "                      s=60, alpha=0.7, color='lightblue')\n",
    "    axes[0,1].set_xlabel('Win Rate (%)')\n",
    "    axes[0,1].set_ylabel('Average Points')\n",
    "    axes[0,1].set_title('Win Rate vs Average Points')\nelse:\n",
    "    axes[0,1].text(0.5, 0.5, 'No points data available', \n",
    "                   transform=axes[0,1].transAxes, ha='center')\n",
    "\n",
    "# Win rate categories\n",
    "win_rate_bins = [0, 10, 20, 30, 40, 50, 100]\n",
    "win_rate_labels = ['0-10%', '10-20%', '20-30%', '30-40%', '40-50%', '50%+']\n",
    "success_df['win_rate_category'] = pd.cut(success_df['win_rate'], bins=win_rate_bins, \n",
    "                                        labels=win_rate_labels, include_lowest=True)\n",
    "category_counts = success_df['win_rate_category'].value_counts()\n",
    "axes[1,0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "axes[1,0].set_title('Distribution of Win Rate Categories')\n",
    "\n",
    "# Performance count distribution for successful pieces\n",
    "axes[1,1].hist(success_df['performances'], bins=20, color='mediumseagreen', alpha=0.7)\n",
    "axes[1,1].set_xlabel('Performance Count')\n",
    "axes[1,1].set_ylabel('Number of Successful Pieces')\n",
    "axes[1,1].set_title('Performance Distribution of Successful Pieces')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n\n",
    "# Statistical insights\n",
    "print(\"\\nüìà Success Rate Insights:\")\n",
    "print(f\"Mean win rate: {success_df['win_rate'].mean():.1f}%\")\n",
    "print(f\"Median win rate: {success_df['win_rate'].median():.1f}%\")\n",
    "print(f\"Pieces with >50% win rate: {(success_df['win_rate'] > 50).sum()}\")\n",
    "print(f\"Perfect win rate pieces (100%): {(success_df['win_rate'] == 100).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Composer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze composers\n",
    "composer_stats = df.groupby('composer').agg({\n",
    "    'title': 'count',\n",
    "    'performances': 'sum',\n",
    "    'wins': 'sum',\n",
    "    'win_rate': 'mean',\n",
    "    'avg_points': 'mean'\n",
    "}).rename(columns={'title': 'piece_count'})\n",
    "\n",
    "# Filter composers with multiple pieces\n",
    "prolific_composers = composer_stats[composer_stats['piece_count'] >= 2].sort_values('performances', ascending=False)\n",
    "\n",
    "print(f\"üéº Analysis of {len(prolific_composers)} composers with 2+ pieces in database\")\n",
    "print(\"\\nüèÜ Top 15 Most Performed Composers:\")\n",
    "display(prolific_composers.head(15).style.format({\n",
    "    'win_rate': '{:.1f}%',\n",
    "    'avg_points': '{:.1f}'\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composer visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Top composers by total performances\n",
    "top_by_performances = prolific_composers.head(10)\n",
    "axes[0,0].barh(range(len(top_by_performances)), top_by_performances['performances'], \n",
    "               color='steelblue', alpha=0.7)\n",
    "axes[0,0].set_yticks(range(len(top_by_performances)))\n",
    "axes[0,0].set_yticklabels([name[:20] for name in top_by_performances.index])\n",
    "axes[0,0].set_xlabel('Total Performances')\n",
    "axes[0,0].set_title('Top 10 Composers by Total Performances')\n",
    "\n",
    "# Composers by average win rate (min 3 pieces)\n",
    "successful_composers = prolific_composers[prolific_composers['piece_count'] >= 3].sort_values('win_rate', ascending=False)\n",
    "if not successful_composers.empty:\n",
    "    top_success = successful_composers.head(8)\n",
    "    axes[0,1].barh(range(len(top_success)), top_success['win_rate'], \n",
    "                   color='darkgreen', alpha=0.7)\n",
    "    axes[0,1].set_yticks(range(len(top_success)))\n",
    "    axes[0,1].set_yticklabels([name[:20] for name in top_success.index])\n",
    "    axes[0,1].set_xlabel('Average Win Rate (%)')\n",
    "    axes[0,1].set_title('Most Successful Composers (3+ pieces)')\nelse:\n",
    "    axes[0,1].text(0.5, 0.5, 'Insufficient data', transform=axes[0,1].transAxes, ha='center')\n",
    "\n",
    "# Piece count vs average win rate\n",
    "axes[1,0].scatter(prolific_composers['piece_count'], prolific_composers['win_rate'], \n",
    "                  s=80, alpha=0.7, color='purple')\n",
    "axes[1,0].set_xlabel('Number of Pieces')\n",
    "axes[1,0].set_ylabel('Average Win Rate (%)')\n",
    "axes[1,0].set_title('Composer Productivity vs Success')\n",
    "\n",
    "# Distribution of pieces per composer\n",
    "axes[1,1].hist(composer_stats['piece_count'], bins=range(1, composer_stats['piece_count'].max()+2), \n",
    "               color='orange', alpha=0.7)\n",
    "axes[1,1].set_xlabel('Number of Pieces per Composer')\n",
    "axes[1,1].set_ylabel('Number of Composers')\n",
    "axes[1,1].set_title('Distribution of Composer Productivity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Division Constraints and Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze division constraints\n",
    "constraints = DivisionConstraints.get_constraints()\n",
    "print(\"üéØ Division Time Constraints:\")\n",
    "\n",
    "constraints_df = pd.DataFrame([\n",
    "    {'Division': name, 'Max Minutes': constraint.max_minutes, 'Max Pieces': constraint.max_pieces}\n",
    "    for name, constraint in constraints.items()\n",
    "])\n",
    "\n",
    "display(constraints_df)\n",
    "\n",
    "# Analyze pieces with duration data against constraints\n",
    "duration_pieces = enriched_df[enriched_df['duration_minutes'].notna()]\n",
    "\n",
    "if not duration_pieces.empty:\n",
    "    print(f\"\\n‚è±Ô∏è Duration Analysis ({len(duration_pieces)} pieces with duration data):\")\n",
    "    \n",
    "    # Check which divisions each piece could fit into\n",
    "    for _, piece in duration_pieces.iterrows():\n",
    "        suitable_divisions = []\n",
    "        for div_name, constraint in constraints.items():\n",
    "            if piece['duration_minutes'] <= constraint.max_minutes:\n",
    "                suitable_divisions.append(div_name)\n",
    "        \n",
    "        print(f\"'{piece['title'][:30]}...' ({piece['duration_minutes']:.1f} min) -> Suitable for: {', '.join(suitable_divisions)}\")\nelse:\n",
    "    print(\"\\nNo duration data available for constraint analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize duration constraints\n",
    "if not duration_pieces.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Duration distribution with constraint lines\n",
    "    axes[0].hist(duration_pieces['duration_minutes'], bins=15, alpha=0.7, color='teal')\n",
    "    axes[0].set_xlabel('Duration (minutes)')\n",
    "    axes[0].set_ylabel('Number of Pieces')\n",
    "    axes[0].set_title('Piece Duration Distribution')\n",
    "    \n",
    "    # Add constraint lines\n",
    "    colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'brown', 'pink']\n",
    "    for i, (div_name, constraint) in enumerate(constraints.items()):\n",
    "        axes[0].axvline(constraint.max_minutes, color=colors[i % len(colors)], \n",
    "                       linestyle='--', alpha=0.8, label=f'{div_name}')\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Constraint compatibility matrix\n",
    "    compatibility_data = []\n",
    "    for _, piece in duration_pieces.iterrows():\n",
    "        row = [piece['title'][:20]]\n",
    "        for div_name, constraint in constraints.items():\n",
    "            row.append(1 if piece['duration_minutes'] <= constraint.max_minutes else 0)\n",
    "        compatibility_data.append(row)\n",
    "    \n",
    "    if compatibility_data:\n",
    "        compatibility_df = pd.DataFrame(compatibility_data, \n",
    "                                      columns=['Piece'] + list(constraints.keys()))\n",
    "        \n",
    "        # Create heatmap\n",
    "        heatmap_data = compatibility_df.set_index('Piece')\n",
    "        sns.heatmap(heatmap_data.T, annot=True, cmap='RdYlGn', \n",
    "                   cbar_kws={'label': 'Compatible (1) / Too Long (0)'}, ax=axes[1])\n",
    "        axes[1].set_title('Piece-Division Compatibility Matrix')\n",
    "        axes[1].set_xlabel('Pieces')\n",
    "        axes[1].set_ylabel('Divisions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"No duration data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights\n",
    "print(\"üîç KEY INSIGHTS FROM 40+ YEARS OF COMPETITION DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall statistics\n",
    "total_pieces = len(df)\n",
    "total_performances = df['performances'].sum()\n",
    "avg_performances = df['performances'].mean()\n",
    "\n",
    "print(f\"\\nüìä OVERALL STATISTICS:\")\n",
    "print(f\"‚Ä¢ Total unique pieces: {total_pieces:,}\")\n",
    "print(f\"‚Ä¢ Total performances: {total_performances:,}\")\n",
    "print(f\"‚Ä¢ Average performances per piece: {avg_performances:.1f}\")\n",
    "\n",
    "# Popular pieces insights\n",
    "most_popular = popular_df.iloc[0]\n",
    "print(f\"\\nüèÜ POPULARITY INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Most popular piece: '{most_popular['title']}' by {most_popular['composer']} ({most_popular['performances']} performances)\")\n",
    "print(f\"‚Ä¢ Pieces with 10+ performances: {(df['performances'] >= 10).sum()}\")\n",
    "print(f\"‚Ä¢ Pieces performed only once: {(df['performances'] == 1).sum()} ({(df['performances'] == 1).sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Success rate insights\n",
    "if not success_df.empty:\n",
    "    highest_success = success_df.iloc[0]\n",
    "    print(f\"\\nüéñÔ∏è SUCCESS INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ Highest win rate: '{highest_success['title']}' by {highest_success['composer']} ({highest_success['win_rate']:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Average win rate (successful pieces): {success_df['win_rate'].mean():.1f}%\")\n",
    "    print(f\"‚Ä¢ Pieces with perfect win rate (100%): {(success_df['win_rate'] == 100).sum()}\")\n\n",
    "# Set piece insights\n",
    "if not set_df.empty:\n",
    "    mandatory_pieces = set_df[set_df['percentage_of_division'] == 100.0]\n",
    "    print(f\"\\nüéØ SET TEST PIECE INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ Confirmed mandatory pieces (100% performance rate): {len(mandatory_pieces)}\")\n",
    "    print(f\"‚Ä¢ Years with most set pieces: {set_df['year'].value_counts().head(3).index.tolist()}\")\n",
    "    print(f\"‚Ä¢ Divisions with most set pieces: {set_df['division'].value_counts().head(3).index.tolist()}\")\n\n",
    "# Composer insights\n",
    "top_composer = composer_stats.loc[composer_stats['performances'].idxmax()]\n",
    "print(f\"\\nüéº COMPOSER INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Most performed composer: {composer_stats['performances'].idxmax()} ({top_composer['performances']} total performances)\")\n",
    "print(f\"‚Ä¢ Composers with multiple pieces: {len(prolific_composers)}\")\n",
    "print(f\"‚Ä¢ Average pieces per composer: {composer_stats['piece_count'].mean():.1f}\")\n",
    "\n",
    "# Duration insights\n",
    "if not duration_pieces.empty:\n",
    "    print(f\"\\n‚è±Ô∏è DURATION INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ Pieces with duration data: {len(duration_pieces)} ({len(duration_pieces)/len(enriched_df)*100:.1f}% of enriched sample)\")\n",
    "    print(f\"‚Ä¢ Average piece duration: {duration_pieces['duration_minutes'].mean():.1f} minutes\")\n",
    "    print(f\"‚Ä¢ Duration range: {duration_pieces['duration_minutes'].min():.1f} - {duration_pieces['duration_minutes'].max():.1f} minutes\")\n    \n",
    "    # Check constraint violations\n",
    "    too_long_for_lower = (duration_pieces['duration_minutes'] > 15).sum()\n",
    "    print(f\"‚Ä¢ Pieces too long for divisions 3-7 (>15 min): {too_long_for_lower}\")\n\nprint(f\"\\nüí° RECOMMENDATIONS FOR CONDUCTORS:\")\nprint(f\"‚Ä¢ Focus on pieces with 3+ performances for reliable success data\")\nprint(f\"‚Ä¢ Consider both popularity and success rate when selecting repertoire\")\nprint(f\"‚Ä¢ Pay attention to time constraints - many pieces exceed lower division limits\")\nif not set_df.empty:\n    print(f\"‚Ä¢ Be aware of historical mandatory pieces when analyzing 'popularity'\")\nprint(f\"‚Ä¢ Explore works by top composers like {composer_stats['performances'].idxmax()}\")\n\nprint(f\"\\nüìà FUTURE ANALYSIS OPPORTUNITIES:\")\nprint(f\"‚Ä¢ Expand WindRep.org enrichment for more duration and grade data\")\nprint(f\"‚Ä¢ Develop program optimization algorithms using time constraints\")\nprint(f\"‚Ä¢ Analyze repertoire trends over time and by geographic region\")\nprint(f\"‚Ä¢ Create recommendation engine based on orchestra grade level and division\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key datasets for further analysis\n",
    "print(\"üíæ Exporting analysis results...\")\n",
    "\n",
    "# Create output directory\n",
    "from pathlib import Path\n",
    "output_dir = Path('../data/notebook_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export popular pieces\n",
    "popular_df.to_csv(output_dir / 'popular_pieces_analysis.csv', index=False)\n",
    "print(f\"‚úì Exported popular pieces to {output_dir / 'popular_pieces_analysis.csv'}\")\n",
    "\n",
    "# Export successful pieces\n",
    "if not success_df.empty:\n",
    "    success_df.to_csv(output_dir / 'successful_pieces_analysis.csv', index=False)\n",
    "    print(f\"‚úì Exported successful pieces to {output_dir / 'successful_pieces_analysis.csv'}\")\n",
    "\n",
    "# Export enriched pieces\n",
    "if not enriched_df.empty:\n",
    "    enriched_df.to_csv(output_dir / 'enriched_pieces_analysis.csv', index=False)\n",
    "    print(f\"‚úì Exported enriched pieces to {output_dir / 'enriched_pieces_analysis.csv'}\")\n",
    "\n",
    "# Export set pieces\n",
    "if not set_df.empty:\n",
    "    set_df.to_csv(output_dir / 'set_test_pieces_analysis.csv', index=False)\n",
    "    print(f\"‚úì Exported set test pieces to {output_dir / 'set_test_pieces_analysis.csv'}\")\n",
    "\n",
    "# Export composer analysis\n",
    "prolific_composers.to_csv(output_dir / 'composer_analysis.csv')\n",
    "print(f\"‚úì Exported composer analysis to {output_dir / 'composer_analysis.csv'}\")\n",
    "\n",
    "print(f\"\\nüìÅ All analysis results exported to: {output_dir}\")\n",
    "print(\"\\n‚úÖ Analysis complete! This notebook provides comprehensive insights into 40+ years of Norwegian Wind Band competition data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
